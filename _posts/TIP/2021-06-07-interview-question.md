---
layout: post
title: 면접 질문 & 나의 프로젝트 간단 요약 
subtitle: "tip,interview"
categories: tip
tags: interview
comments: true
---


## 예상 질문
- 1분 자기소개
  : 안녕하세요 클린코드를 지향하는 지원자 떙떙떙입니다.    
    학부시절 7개의 프로젝트 경험이 있습니다. 프로젝트를 통해 CS를 학습하였다고 생각합니다. 그때 작성한 코드는 스파게티 코드였다고 생각이 됩니다. 왜냐하면 코드의 가독성이 없었기 때문입니다. 하지만 지금은 리팩터링에 관심 많고 이해하기 쉬운코드, 효율적인 코드 작성을 노력중입니다.    
    이런 노력을 통해 앞으로는 백엔드 개발자로 전문성을 키우고 싶습니다.    
    전문성을 키우고자 spring,docker,git,DB 등을 학습하고 블로그에 기록하고 있습니다.   
    싸피를 통해 효율적인 코드, 협업, 전문성을 키우고 싶은 0년차 백엔드 주니어입니다.

- 가장 자신있어 하는 것은 무엇인가요?
  : 

- 관심 있는 IT 동향은 무엇인가요?
  : 대용량 처리를 위해서 클러스터링, 레플리카는 어떻게 구성하는지 그리고  k8s는 어떻게 구성하고 , 카프카, 이벤트소싱, CQRS는 어떻게 구성하고 사용하는지 관심이 많습니다. 

- 본인의 장점과 단점
  : 쉽게 포기 하지 않는 장점이 있다고 생각합니다. 프로젝트를 진행하면 항상 밤을 새는 경우가 많았습니다. 하고싶은게 많은데 잘 안 되었기 때문에 밤새 몰두하는 경우가 많았습니다. 사소한 기능이라도 끝끝내 구현에 이르면 개발에 재미를 느끼곤 했습니다. 이런 경험의해서 저는 끈기가 있다고 생각합니다.   
  : 단점은 하나에 깊게 파고들다 보면 주변을 보지 못하는 단점이 있습니다. 밤새도록 코드작성 및 레퍼런스 검색을 하다보면 다른것에 집중하지 못 할때가 많았습니다.

  쉽게 아는척하기 하는게 저의 단점이었습니다. 작은것이라도 알고있으니 잘안다고 생각했습니다. 하지만 컴퓨터를 학습하면서 내가 아는것이 정말 정확한가?? 알지도 못하면서 아는척하면 나에게나 남에게 엄청난 피해라는 것을 알게 되었고 
  저는 이 단점을 작은것 하나라도 논리적으로 알며 명확하게 아는것만 말하고자 의식하고 있습니다. 
  

- 지원동기
  : 문제해결을 위한 알고리즘 , 진정한 협업을 경험하고자 지원하게 되었습니다.    
  저는 학부시절 7개의 프로젝트를 진행하였는데 그중 5개를 같은 팀원과 진행하였습니다. sns로 버전관리, 주먹구구식 소통 등의 협업을 경험하였습니다. 그당시의 협업은 현재 제가 하고싶은 협업은 아니였다 라는 생각이 듭니다.    
  저는 싸피에서 코드리뷰, git flow,pull request, CICD, 등 다양한 방법을 통해서 제대로 된 협업을 경험하고 싶습니다.    
  이런 과정 중에 효율적 알고리즘에 의한 더빠른 , 더 이해하기 쉬운 코드를 작성방법을 배우고 싶습니다.    
  알고리즘과 협업을 학습하고 경험하고 싶어 지원하게 되었습니다.   

- 마지막으로 하고싶은말
  : 싸피 설명회 통해서 코드리뷰가 진행됨을 알고있습니다. 이외에도 싸피 동기간 개발서적 스터디, 짝프로래밍등 다양한 IT문화를 경험할 수 있는 시스템이 있는지 궁금합니다.  

- 어려움을 해결한 경험
  : 

- 동료와의 갈등 , 해결 경험
  : c로 keyvalueStore 구현해야했습니다. 4학년과 팀이 되었고 제가 너무 프로그래밍 능력이 부족하다고 핀잔을 주었습니다. 맞는말이지만 기분은 좋지 않았습니다. 
  그렇다고 여기서 제가 아무것도 안할수는 없기에 오히려 더 열심히 자료구조를 공부하고 i/o는 어떻게 받을지 준비를 많이 해갔습니다. 
  팀원이 저의 정성을 보았나 제가 부족한 부분을 많이 알려주었고 둘 사이의 갈등 또한 사라졌습니다. 
  플젝이 끝난뒤에 저는 내가 이런상황에서 팀원처럼 해야겠다는 다짐을 하였습니다. 정말 거의 모든걸 알려주었는데 저또한 열심히 배우려고 하였습니다. 
  비트리와 해쉬를 사용하여 키밸류스토어를 구현할수있었고 좋은 프로젝트 결과를 얻을수있었습니다.

- 전공자인 내가 싸피를 교육이수의 메리트는 ? (나는 협업, 알고리즘)
  : 저는 알고리즘, 협업능력이 부족하다고 생각됩니다. 또한 이것들은 제가 잘하고 싶은 영역입니다.   
  싸피를 통해 알고리즘,협업능력을 키울수있다고 알려져있습니다. 물론 혼자서도 할수있지만 싸피에서의 피드백을 받고 싶습니다. 멘토의 피드백, 동기의 피드백 이러한 IT문화를 경험하고 싶습니다. 또한 제가 아는것은 다 알려주고 싶습니다. 
  이런 과정을 통해서 제가 성장 할 수 있다고 생각하기 떄문에 전공자인 제가 싸피를 이수하고 싶은 이유입니다. 

  : 저는 학부시절 협업의 기회를 날렸습니다. sns를 통한 주먹구구식의 개발을 진행 하였습니다. 
  저는 싸피를 통해서 협업의 기회, 동료를 얻고 싶습니다. 
  피드백을 주고 받는 동료!! 이러한 IT문화를 경험함으로서 저의 개발ㅁ역량을 늘리고 싶습니다. 
  이러한 이유로 싸피는 전공자인 제가 놓쳤던 기회를 다시 잡는 시간이라고 생각하며 싸피 지원한 이유입니다. 

- 취업해서 배우는게 더 나은거 아니야 ?
  협업을 경험하고 싶습니다. 커뮤니트를 통해서도 구하였지만, 결속력이 많이 부족하였습니다. 그래서 싸피를 통해 동료를 얻고 싶습니다.   
  알고리즘,협업의 중요성이 강조되고 있습니다. 저는 이러한 부분이 약하고 더욱 학습하고 싶습니다. 그렇기에 싸피를 통해서 더 배우고 싶습니다. 실무수준의 협업을 배우고 싶습니다. 

- 자신만의 경쟁력
  : 도전의식이 저의 경쟁력이라고 생각합니다. 안될걸 아는데 도전합니다. 한번에 안되겠지만 여러번 도전하다보면 언젠간 될거라는 믿음이 있습니다. 이러한 마인가 저의 경쟁력이라고 생각합니다. 
  이는 꾸준함이 될수도 있겠고, 논리적인 사고능력이 될수도 있으리라 생각합니다. 

- 인상깊게 들은 과목
  : 운영체제가 인상 깊었습니다. 컴퓨터가 동작하는 과정을 학습하기 때문이고 cli를 직접적으로 사용하기 때문에 당시에 인상깊었습니다. 
  현재 인상깊은 과목을 선택하여도 역시 운영체제입니다. 운영체제에서 학습한 스케줄링, 운영체제 구성 내용등이 결국 응용소프트웨어에서도 사용되기 때문입니다. 


- 좋아하는 일과 잘하는 일중 선택해야한다면 무엇을? 
  : 잘하는일 선택해야합니다. 회사의 이익이든 본인의 이익이든 일을 통해 생산적인 결과물을 나타내야 하기 때문입니다. 좋아하는 일이라는 것은 저의 이익으로 대변되는 부분이고 이것은 개인시간을 이용해서 활용해야 한다고 생각합니다. 

- 대인관계에 관한 질문
  : 저의 좋은게 좋은거다 라는 마인드로 대인관계를 유지합니다. 그리고 경청의 중요성을 알고있습니다. 하지만 프로젝트등의 목적이 분명한 경우 명확한 요구를 요하는 스타일 입니다.   
  질문을 할때에 상대의 시간을 위해 스스로 최대한 알아보고 이러한 시도를 했다고 알린 뒤 질문을 하곤 합니다. 
  대인관계가 나빠지면 이는 상대와 본인 둘 다 문제가 존재한다고 생각합니다. 본인의 잘못을 인지하는 과정이 필요하며 이를 상대방과 공유할수 있어야 할 것으로 생각합니다. 

- 창의력을 발휘한 경험은 ?
  
- 지원자는 리더형인가 팔로워형인가?

  


- 어떠한 개발자가 되고 싶나요
- 자소서 기반으로 어떻게 진행되었는지 
- 알고리즘 


피티 면접   
AI, 빅데이터(4차산업혁명) 를 적용해서 어떻게 응용을 할수있겠는가? 


같은 프로세스 다른 디비
상품목록을 레디스와같은 저장소에 캐싱하고  쿼리 모델을 레디스를 사용하는 방식이죠
명령이 데이터를 변경하면 변경내역을 쿼리쪽 디비에 전달하게 됩니다. 

다른 다른
명령이 데이터에 변경하면 이 내역을 쿼리쪽에 전달해야합니다. 
MSA에서 사용하는 방식입니다. 

전달방법
1 명령이 직접 쿼리디비를 수정하는 방식이에요.
  카프카 같은 메시징을 이용해서 전달하는 방법도 있습니다. 
  이방법은 데이터 유실 가능성이 존재합니다. 
  문제가 발생하게되면 쿼리디비에 반영해야할 데이터가 유실될수있다.
  쿼리디비나 메세징의 문제때문에 명령을 수행하는것 자체가 에러가 날수있다. 

2 두번째는 명령디비에 기록하고 별도의 전파기를 통해서 쿼리디비에 전달하는 방식이에요
  일단 명령을 상태를 변경한 다음에 뭘 바꿨는지 별도의 테이블에 기록을 합니다. 이과정은 한 트랜잭션으로 처리되기 떄문에 데이터가 유실되지 않는 장점이 있다. 
  이때 전파기를 따로 구현해야하는 단점이 존재하다.

3 디비가 제공하는 CDC를 사용하는 방법입니다. 
  예를 들면 디비의 바이너리 로그를 읽어서 변경데이터를 확인하고 이를 쿼리쪽에 전달하는 방식이다. 
  명령쪽 코드에서 변경내역을 따로 저장하지 않아도 되니깐 명령코드가 단순해지는 장점이 존재합니다. 

주의할점
  데이터 유실 : 유실 허용여부에 따라 DB트랜잭션 범위가 중요
  허용가능 지연 시간 : 명령의 반영내역을 얼마나 빨리 반영해야하는가 등의 허용가능한 지연시간이 존재하고 이를 고려해야한다.
  중복전달 : 유실을 고려해서 다시전달 할 수 있는 방법을 만들게 되면 쿼리쪽에 이미 반영된 데이터를 중복으로 전달한 경우도 발생하게 될것이다. 이때 쿼리쪽 데이터가 망가지지 않도록 별도의 처리를 해야합니다. 
  
  이외에도 다른 주의사항도 존재합니다. 


정리 cqrs는 명령 역할을 수행하는 구성요소와 쿼리 역할을 수행하는 구성요소를 나누는것을 cqrs라고 함
왜하냐?
     1 명령과 쿼리는 다루는 데이터가 다름 
     2 명령과 쿼리는 코드 변경 빈도/사용자가 다름
     3 기능 마다 성능 요구가 다름



## 카프카 (분산 이벤트 스트리밍 플랫폼 - 하이포퍼먼스)

1. 기본구조 
  - 카프카 클러스터 : 메시지를 저장하는 저장소이다. 하나의 카프카 클러스터는 여러개의 브로커로 구성된다. 
    - 브로커는 각각의 서버라고 생각하면 된다. 
    - 브로커들이 메세지를 나눠서 처리하고 이중화도 하고, 장애 대체의 역할을 수행한다.
  - 주키퍼클러스터 (앙상블) : 카프카 클러스터를 관리한다. 주키퍼속에 카프카 클러스터의 정보과 관리된다. 
  - 프로듀서 : 카프카에 메세지를 넣는 역할을 한다. 
  - 컨슈머 : 메시지를 카프카에서 읽음

2. 토픽과 파티션
  - 토픽 : 메시지를 구반하는 단위 ex) 뉴스용 토픽, 메일토픽 ... 즉 파일시스템의 폴더와 유사
  - 한 개의 토픽은 한개 이상의 파티션으로 구성
    - 파티션은 메시지를 저장하는 물리적인 파일
  
  - 파티션 : 추가만 가능한 파일(append-only)
    - 각 메시지 저장 위치를 오프셋 이라고 함
    - 프로듀서가 넣은 메시지는 파티션의 맨 뒤에 추가
    - 컨슈머는 오프셋 기준으로 메시지를 순서대로 읽음
    - 메시지는 삭제되지 않음(설정에 따라 일정 시간이 지난뒤 삭제)

  - 여러 파티션과 프로듀서
   - 프로듀서는 라운드로빈 또는 키로 파티션 선택
   - 같은키를 갖는 메시지는 같은 파티션에 저장 -> 같은 키는 순서 유지

  - 여러 파티션과 컨슈머
    - 컨슈머는 컨슈머그룹에 속함
    - 한개 파티션은 컨슈머그룹의 한 개 컨슈머만 연결가능
      - 즉 컨슈머그훕에 속한 컨슈머들은 한 파티션을 공유할 수 없음
      - 한 컨슈머그룹 기준으로 파티션의 메시지는 순서대로 처리

3. 성능
  - 파티션 파일은 os 페이지 캐시 사용
    - 파티션에 대한 파일 IO를 메모리에서 처리
    - 서버에서 페이지캐시를 카프카만 사용해야 성능에 유리
  - Zero Copy
    - 디스크 버퍼에서 네트워크 버퍼로 직접 데이터 복사
  - 컨슈머 추적을 위해 브로커가 하는 일이 비교적 단순
    - 메시지 필터, 메시지 재전송과 같은 일은 브로커가 하지 않음
      - 프로듀서,컨슈머가 직접 해야 함
    - 브로커는 컨슈머와 파티션 간 매핑 관리

  - 묶어서 보내기, 묶어서 받기 (batch)
    - 프로듀서 : 일정 크기만큼 메시지를 모아서 전송가능
    - 컨슈머: 최소 크기만큼 메시지를 모아서 조회 가능
  - 낱개 처리보다 처리량 증가 
  - 처리량 증대(확장)가 쉬움
    - 1개 장비의 용량 한계 -> 브로커 추카, 파티션 추카
    - 컨슈머가 느림 ->컨슈머 추가(+파티션 추가)

  - 리플리카 : 파티션의 복제본
    - 복제수(replication factor) 만큼 파티션의 복제본이 각 브로커에 생김
  - 리더와 팔로워 구성
    - 프로듀서와 컨슈머는 리더를 통해서만 메시지 처리
    - 팔로워는 리더로부터 복제
  - 장애 대응 
    - 리더가 속한 브로커 장애시 다른 팔로워가 리더가 됨

4. 프로듀서 
  - 

  




## 프로그래밍 초식 
1. 변수아끼끼 : 의미를 더해주는 변수 위주로 사용하기 (식이 복잡하거나 길어지 ㄹ경우 변수 이름으로 설명)
  - 가능한 선언과 값 할당을 한번에 하자 
  - 최대한(절대로) 변수의 용도/의미 변경 X : 의미나 용도가 다르면 다른 변수 사용할것 (이러면 개발자들이 코드를 이해가 어려워진다. )
  - 변수가 사용되는 코드 범위를 최소화하기 ex) forloop만을 위한 코드를 작성하라 
    ```
        for(Some some : somes){
            String msg = some.getName() + ~~
        }

        =====================

        .... (코드 10줄)
        String msg = ...;
        return Result.message(msg);
    ```
  - 변수를 아끼는 연습하기 
  - 중요한 코드의 복잡도를 낮추고 가독성을 높이는 쉬우 방법 -> 변수 아끼고 변경 줄이고 범위 좁히고 

2. 나누기 
  - 구현기술을 여러 기본기 하나이다. 
  - 초짜 특징 중 하나 : 점점 커지는 함수/메서드/클래스
  - 너무 커지면 프로그램 분석이 어려워짐(수정이 어려워짐)
     - 흔한 예: 
       - if-else, if 중첩이 복잡해짐
       - 변수의 의미가 중간에 바뀜
       - 코드 안에서 중복이 발생함
  - 의미가 있는 단위로 코드/구성 요소를 나누는 기술 : 나누기
  - 패턴은 전형적인 예
    - 웹개발 : 컨트롤러 - 서비스 - DAO
    - DDD : 엔티티, 밸류, 리포지토리
    - 디자인 패턴: 빌더, 어댑터, 컴포지트 등
  - 나누기는 곧 기능 분해/분리 : 기능은 여러 작은 기능/로직(하위 기능)으로 구성
  - 나눈 하위 기능을 메서드나 클래스로 분리 : 나누기의 결과
    ```
    OrderRepository : DB에서 주문 데이터 읽기, DB에서 변경데이터 쓰기
    Order : 주문 취소 가능여부 확인, 주문데이터 변경
    OrderCancelService : 취소 처리 흐름제어 
    Notifier : 취소 결과 통지 
    PayCancelService : 결제 취소
    ```
  - 나누기는 역할/책임 도출 인것이다. 
  - 어떤 기준으로 나누나? : 정답은 없음 하지만 보통은 기능에서 의미가 있는 하위 기능 단위로 나누는 시도를 추천
    - 주문취소 기능 : 취소의 입장에서 의미있는 단위 
      - 취소 사싱 통지 vs push 테이블에 insert
      - 결제 승인 취소 vs pg사가 제공하는 API 실행
    - 대칭성 활용의 측면
      - 취소는 취소끼리 비슷한 기능끼리 나눈다. (코드간의 수준을 맞춘다.)
  - 나눈결과 
    - 나누기를 안하면 
      - 코드 순서대로 구현을 이해하는 것이 가능
      - 근데 코드가 커질수록 코드가 복잡해져서 점점 이해하기 어려워짐
      - 코드가 커질수록 변경도 어려워짐
    - 나누기를 잘하면 
      - 구조의 복잡도가 증가하지만 상위 수준에서 실행 흐름 이해하기 좋음
      - 코드 변경이 (나누기 전보다 ) 쉬워질 가능성이 높아짐 
    - 너무 잘게 나누면
      - 너무 복잡해져서 실행 흐름을 이해하기 어려워짐
      - 변경할 떄 수정 대상이 많아져 변경이 어려워짐

3. WHAT,HOW
  - 하려는것/의미/의도(WHAT) - 그것의 실제 구현(HOW)

    |what|how|
    |------|---|
    |가입한지 1년 미만|user 테이블에서 reg칼럼 값 기준으로 count|
    | 추가 지급 내역 남김|log 테이블에 insert|
    
    `의미가 들어나게 생각해보고 이를 코드로 만드는 연습을 해라 !`

    ```
    int addPointRate = 0;
    if(userRegistedLessThanOneYear(userId)){
        addPointRate = 1;
    }
    ...
    if(addPointRate > 0){
        recordAddPointHistory(userId,addPointRate);
    }
    ```
    
  - what 최대한 드러나게 생각을 하자(슈도코드 등등) -> 그리고 실제로 코드상에서 어떻게 이를 적용할지 생각한다(의도가 드러나게 !)

  - WHAT,HOW 분리 결과
    - 구현을 잠시 잊고 실제 하려는 것이 무엇인지 생각하게 됨
      - 실제 하려는 것이 코드에 표현될 가능성이 높아짐
      - 코드의 가독성이 향상
      - 유지보수성이 좋아짐
    - 물론 구현 제약등의 이유로 표현력이 떨어질 경우도 존재함

  - 평소에 의식의 흐름대로 막 구현만 하면 안됨
    - 의미/의도가 드러나는 코드를 작성하도록 노력해야함
    - 연차가 쌓인다고 절로 늘지 않음
  

대부분 우리나라에서 잘안쓰는 경우를 덜 유용하다고 느낄수있스니다. 지도나 애플페이를 쓸수있다고 한다라더 한국매출이 그렇게 작은 편이 아니에요 사파리 디자인이 많이 바꼈어요 왜 쓸만하지 잠깐만 나쁘지않아 이렇게 인터페이스가 바꼈어요 이걸 쑉하면 탭 그룹이 생겨서 묶어서 관리할수 아이플러스라는게 생겼어요 비공게 

---
데이터웨어하우스 
====
**정의**
 
  - 비즈니스 범위를 넘은 데이터들의 집합으로 표현한다.
  - 다수의 핵심적인 거래처리 시스템들로부터 현재 및 과거 데이터들을 저장함
  - 전사적인 사용ㅇ을 위해 정보를 통합하고 표준화하지만 변경은 할수없음
  - 분석 및 리포팅을 목적으로 함

**주제지향성**
  - DB : 업무기능 중심
  - DW : 특정주제에 따른 분류

**특징**

  - 데이터의 통합성 : 여러DB의 다양한 포맷을 공통된 처리화를 진행하여 DW에 저장한다.
  - 데이터의 시계열성
  - 데이터의 비휘발성
  
  - ETT(추출,변형,전송) : 데이터웨어하우스를 구축하고 활용해나가는 일련의과정을 의미 

**데이터 마트**

  - 편리한 데이터웨어하우스 구성을 위해 데이터마트 구성
  - 데이터웨어하우스의 일부분
  - 특정 사용자 집단이 사용할 수 있도록 특정 초점을 가지고 요약된 조직 데이터의 일부분
  - 초점은 일잔적으로 단일주제 영역이나 업무 영역에 맞춤

  - 데이터마트와 데이터웨어하우스 차이
    - 데이터의 용령과 사용자 규모에서 차이가 있을 뿐 ETT도구, 운영 데이터베이스 및 DBMS, 분석도구등의 기본 구성요소는 동일

**CRM**

  - DB,DW를 기반으로 분석하는 시스템을 CRM이라고 한다.
  - 운영, 분석이 진행된다. 
  




----
빅데이터 처리 프로세스
====

**빅데이터 소스**

  - 내부 데이터 소스
    - 데이터베이스
    - 데이터웨어하우스
    - `입력형식이 정해져 있는 정형화된 데이터`
    - `고정된 필등 의해 저장되는 데이터`
  - 외부데이터 소스
    - (open,여러) API
   

  - 데이터 형식
    - 비정형 데이터(텍스트 마이닝 사용)
      - 웹페이지 
      - SNS
      - 로그 데이터 
      - 센서 데이터 
      - 음성 데이터 
      - 이미지 데이터 (CNN)
    
**빅데이터 수집**
  - 스쿱
    - 기존의 데이터베이스의 내용을 가져와 이를 하둡같은 분산디비에 데이터 수집함
    - 아파치 하둡 기반 프로젝트인 Hive,Pig,Hbase 등과도 호환이 잘되어 RDBMS, NoSQL간의 데이터 연동에 많이 사용됨

  - 플럼 (flume)
    - 이벤트 로그 데이터를 효율적으로 수집 할 수 있는 로그 수집기
    - 여러 서버네서 생산된 대용량 로그 데이터를 효과적으로 수집하여, HDFS과 같은 원격 목적지에 데이터를 전송
    
  - 아파치 스톰 
    - 실시간 데이터 처리를 위한 시스템
    - 시간이 지나감에 따라서 끊임 없이 데이터들을 생성
    - 트위터 스트림을 이용한 소셜 마케팅 반응 분석

  - 크롤링


**빅데이터 처리**

  - 배치 & 일괄배치
  
  - 맵리듀스
  - 빅쿼리(BigQuery) 
  - presto
  - pig
  - hive

**빅데이터 분석**
  - BA
    - 데이터를 분석하는 도구들과 기법
    - 수리적 모델, 통계기법, 데이터마이닝, 기계학습, 딥러닝
    - 의사결정에 필요한 정량적인 데이터를 산출하는 업무, 기술

  - BI
    - 비즈니스에서 발생한 데이터를 수집하고, 저장하고, 분석하는 인프라
    - 데이터베이스, 데이터 웨어하우스, 데이터 마트, 하둡, 분석 플랫폼
    - 온라인분석처리(OLAP), 과거 상황과 현재상황을 이해하기 위한 데이터 시각화 및 리포팅

  > ### BA -> BI로 현재 진행중이다.




  
  







----
빅데이터 저장과 처리 
====

대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임 워크 

하둡 : 맵리듀스,yarn을 가지고 있는 분산된 파일시스템에다 여러가지 기능을 붙인 오픈소스이다.
  - DBMS가 아님 -> 프레임 워크
  - 하둡은 분산시스템인 HDFS에 데이터를 저장하고, 맵리듀스를 이용해 데이터를 처리

분산저장(HDFS - Hadoop Distributed File System) : 빅데이터 파일을 여러 대의 서버에 분산 저장하기 위한 파일 시스템

분산처리(MapReduce) : 각 서버에서 데이터를 분산처리하는 분산 병렬처리를 위한 분석 시스템

**배경**
  - 웹 크롤러 색인 처리 과정에세 생성되는 큰 파일 처리 한계
  - DBMS의 한계를 보여줌
  - 크롤러와 검색 엔진 시스템 성능 향상
  
  - 구글에서 먼저 GFS가 출시됨 (구글 분산 파일 시스템의 논문). 기를 기반으로 하둡이 오픈소스로 발생


**분산**
  - 스케일 업 : 컴퓨터의 자원을 업그레이드 하는 방법 ( 수직적 확장)
  - 스케일 아웃 : 컴퓨터의 수평적인 확장이 일어남 같은 성능의 여러대의 컴퓨터를 구성 ( 클러스터링 된 컴퓨터 )

  구글 파일 시스템은 클러스터링이 존재라고 마스터와 여러개의 슬레이브가 존재합니다.

  마스터(job tracker) 슬레이브 구조에서 TaskTracker를 수행하는 구조가 맵리듀스기 존재하고  
  마스터(name Node) 슬레이브 구조에서 DataNode 를 수행하는  HDFS가 존재한다.


**HDFS**
  - 데이터를 64mb 블록 단위로 데이터 관리하고 이를 slave(node)에 나눠서 저장한다. 
  
  - 마스터 nameNode : 데이터의 메타데이터(전체구조) 관리 
    - 데이터 노드 모니터링 : 3초마다 하트비트를(생존하고 있음을) 전송 
    - 블록관리 : 장애가 발생한 데이터노드의 블록을 새로운 데이터노드에 복제
  - 데이터 노드 
    - 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지
    - 실제 저장되는 데이터 

**MapReduce**
  - 대용량 데이터 처리를 위한 분산 프로그래밍 모델
  - 분산 처리 기술과 관련 프레임워크를 의미
  - Data : 분산DB에 저장됨
  - 처리 : 통합처리 vs 분산처리 

  나눠서 저장하고 한군데에서 처리하면 분산의 의미가 없다. 

  그렇기 때문에 나눠진 저장소에서 처리까지 하는게 맵리듀스이다. 

  분석한 결과를 취합하여 처리하는 방법이다. 

  MapReduce : map + reduce 

  Map : 각각에 분산된 컴퓨터에서 처리해주는 것
      흩어져 있는 데이터를 key,value의 형태로 연관성 있는 데이터 분류로 묶는 작업

  reduce : map에서 나온 output을 통합해주는 과정 reduce라고 합니다. 
      통합해주는 과정이 줄이는 과정이라고 보는것이다. !   
      filtering과 sorting을 거쳐 데이터를 추출, map화 한 작업 중 중복 데이터를 제거 하고 원하는 데이터를 추출하는 작업



**하둡 에코 시스템**

  - 빅데이터 수집 
    - 플럼 : 비정형 데이터 수집
    - 스쿱 : 관계형 DB로부터 데이터 가져오기 
  - 빅데이터 저장, 활용
    - hbase : 컬럼 기반 NoSQL 데이터베이스
  - 빅데이터 처리
    - 하이브 : 유사 SQL 기반 빅데이터 처리
    - 피그 : 스크리브 언어 기반 빅데이터 처리
    - 마후트 : 기계학습 알고리즘 기반 빅데이터 처리
  - 빅데이터 관리 
    - 우지 : 빅데이터 처리 과정 관리 
    - h카탈로그 : 빅데이터 메타 정보 관리
    - 주키퍼 : 빅데이터 서버 시스템 관리

  하둡기반으로 데이터 저장이 되고 이를 빅데이터처리 과정을 거친다. 하이브,피그,마후트 등등으로 구성된다. 


**NoSQL**

  - 비 관계형 데이터 베이스 
  - schema-free : 보다 유연한 데이터 모델 <-> 정형화된 틀(schma) ex)주민번호,학번,성별 등 형식
  - 분산 다수의 하드웨어 걸쳐 저장된 데이터
  - 용이한 데이터 규모 확장성
  - 대용량의 구조적, 반구조적 데이터들을 다룸 (웹, 소셜 미디어, 그래픽)

  
  **NoSQL의 분류**
  - 키밸류 
  - 컬럼 베이스 
  - 도큐먼스 베이스
  - 그래프 베이스 
  

  **아파치 스파크**
   - 하둡시스템을 인메모리로 사용한다는 것
   - in-memory 기반 분산 고성능 클러스터 플랫폼
   - 기존 하둡의 mapreduce 작업을 디스크 기반이 아닌 메모리 기반으로 옮겨 고속화

  
  
  

